{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generation (Step-by-Step)__ \n",
    "---\n",
    "\n",
    "[![colab image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/astro-informatics/s2scat/blob/main/notebooks/manual_generation.ipynb)\n",
    "\n",
    "This tutorial is a basic overview of how one may use the scattering covariances as a statistical generative model. \n",
    "\n",
    "Generative AI models typically require the abundance of realistic training data. In many (often high dimensional) application domains, such as the sciences, such training data does not exist, limiting generative AI approaches.\n",
    "\n",
    "One may instead construct an expressive statistical representation from which, provided at least a single fiducial realisation, many realisations may be drawn. This concept is actually very familiar, particularly in cosmology where it is typical to draw Gaussian realisations from a known power spectrum.  However, this generative model does not capture complex non-linear structural information.\n",
    "\n",
    "Here we will instead use the scattering covariances $\\Phi(x)$ as our statistical representation. Given $\\Phi$ is a non-linear function of the data $x$, generating new realisations isn't quite so straightforward.  In fact, to do so we'll need to minimise the loss function:\n",
    "\n",
    "$$ \\mathcal{L}(x) = ||\\Phi(x) - \\Phi(x_t)||^2_2$$\n",
    "\n",
    "where $\\Phi(x_t)$ are the target covariances computed from the signal we are aiming to emulate $x_t$. To solve this optimisation with gradient based methods we clearly need to be able to differentiate through $\\Phi$ which is a complex function involving wavelet transforms, non-linearities, spherical harmonic and Wigner transforms. \n",
    "\n",
    "As ``S2SCAT`` is a ``JAX`` package, we can readily access these gradients, so lets see exactly how this works! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the package\n",
    "\n",
    "Lets first import ``S2SCAT`` and some basic plotting functions. We'll also pick up ``pickle`` to load the targets which have been stored just to save you some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Install a spherical plotting package.\n",
    "!pip install cartopy &> /dev/null\n",
    "\n",
    "# Install s2fft and data if running on google colab.\n",
    "if IN_COLAB:\n",
    "    !pip install s2scat &> /dev/null\n",
    "    !pip install numpy==1.23.5 &> /dev/null\n",
    "    !mkdir data/\n",
    "    !wget https://github.com/astro-informatics/s2scat/raw/main/notebooks/data/target_map_lss.npy -P data/ &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "import cartopy.crs as ccrs \n",
    "import s2scat, s2fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up the target field we are aiming to emulate, and the hyperparameters of the scattering covariance representation we will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 256                # Spherical harmonic bandlimit.\n",
    "N = 3                  # Azimuthal bandlimit (directionality).\n",
    "J_min = 2              # Minimum wavelet scale.\n",
    "reality = True         # Input signal is real.\n",
    "recursive = False      # Use the fully precompute transform.\n",
    "\n",
    "# Lets load in the spherical field we wish to emulate and its harmonic coefficients.\n",
    "x_t = np.load('data/target_map_lss.npy')\n",
    "xlm_t = s2fft.forward_jax(x_t, L, reality=reality)[:,L-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calling the scattering transform you need to run configuration, which will generate any precomputed arrays and cache them. When running the recurisve transform this shouldn't take much memory at all. However, the fully precompute transform, which is much faster, can be extremely memory hungry at L ~ 512 and above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the representation e.g. load wavelet filters and Wigner matrices.\n",
    "config = s2scat.configure(L, N, J_min, reality, recursive)\n",
    "\n",
    "# Calculate normalisation and target latent vector. \n",
    "norm = s2scat.compute_norm(xlm_t, L, N, J_min, reality, config, recursive)\n",
    "targets = s2scat.scatter(xlm_t, L, N, J_min, reality, config, norm, recursive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a simple $\\ell_2$-loss function which just computes the mean squared error between the scattering covariances computed at our current iterant and those of the target. In practice, any loss could be considered here, however we'll use the most straightforward scenario for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(xlm):\n",
    "    predicts = s2scat.scatter(xlm, L, N, J_min, reality, config, norm, recursive)\n",
    "    return s2scat.optimisation.l2_covariance_loss(predicts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an initial estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose a set of harmonic coefficients $x_{\\ell m}$ from which to start our optimisation. Strictly speaking, we should start from Gaussianly distributed random signal to ensure we form a macro-canonical model of our target field, and we will do precisely this. However, in practice it may be better to start from e.g. a Gaussian random field, generated from a fiducial power spectrum, as this may reduce the total number of iterations required for convergence. \n",
    "\n",
    "In any case, lets generate a starting signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the standard deviation of the target field.\n",
    "sigma_bar = np.std(np.abs(xlm_t)[xlm_t!=0])\n",
    "\n",
    "# Generate Gaussian random harmonic coefficients with the correct variance.\n",
    "xlm = np.random.randn(L, L) * sigma_bar + 1j*np.random.randn(L, L) * sigma_bar \n",
    "\n",
    "# Save the starting noise signal for posterity and plotting!\n",
    "xlm_start = s2scat.operators.spherical.make_flm_full(xlm, L)\n",
    "x_start = s2fft.inverse(xlm_start, L, reality=reality, method=\"jax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimise the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass all these components to ``optax``, which we have internally configured to use the adam optimizer to minimise the loss and return us a synthetic realisation which should approximate the target field statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimisation to generate a new realisation xlm.\n",
    "xlm_end, _ = s2scat.optimisation.fit_optax(xlm, loss_func, niter=400, learning_rate=1e-3, verbose=True, track_history=True)\n",
    "\n",
    "# Convert the synthetic harmonic coefficients into a pixel-space image.\n",
    "xlm_end = s2scat.operators.spherical.make_flm_full(xlm_end, L)\n",
    "x_end = s2fft.inverse_jax(xlm_end, L, reality=reality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets check how our starting and ending realisations shape up against the target field!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [x_t, x_start, x_end]\n",
    "titles = [\"Target\", \"Start\", \"Emulation\"]\n",
    "fig, axs = plt.subplots(1, 3, subplot_kw={'projection': ccrs.Mollweide()}, figsize=(30,10))\n",
    "mx, mn = 3, -1\n",
    "for i in range(3):   \n",
    "    axs[i].imshow(fields[i], transform=ccrs.PlateCarree(), cmap='viridis', vmax=mx, vmin=mn)\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('s2fft')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3425e24474cbe920550266ea26b478634978cc419579f9dbcf479231067df6a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
